---
title: Cloud Analytics Engineering Guide
markdown2extras: wiki-tables, code-friendly
apisections: 
---

# Cloud Analytics Engineering Guide

This document documents the Cloud Analytics code base. For user-facing
documentation, see "Joyent Cloud Analytics" in the same directory.  **Start
with the public facing documentation first, at least the part describing key
abstractions: metrics, fields, etc.**

# Development basics

## Repository overview

Subdirectories in this repo include:

    bamboo                      scripts used by the Bamboo continuous integration system
    build                       (auto-generated by "gmake install")
    build/dist                  release tarball
    build/pkg                   proto area for packages and package tarballs
    cmd                         source files implementing executables (daemons and tools)
    demo                        demos
    demo/basicvis               reference CA web client
    demo/tools                  tools for demo'ing CA
    deps                        library dependencies (see below)
    lib                         source files implementing library code shared by multiple
                                consumers
    metadata                    JSON metadata used to configure CA
    pkg                         npm packaging metadata and scripts
    smf                         SMF manifests and method scripts
    tools                       miscellaneous tools
    tools/jsl                   javascript lint
    tools/jsstyle               javascript style checker based on OpenSolaris's cstyle
    tools/ws                    set up environment for running executables
    tools/catest                run CA test suite
    tools/webrev                generate webrevs
    tools/caupagent             upgrade script for instrumenter agent
    tools/recreate-zone         upgrade script for CA services
    tst                         automated tests

To browse the source, first build a cscope database with:

        # gmake xref

and then launch the cscope browser:

        # cscope -dq


## Dependencies

The project depends on the following components that are assumed to be
installed already on both development and test machines:

* python (for jsl only)
* perl (for jsstyle only)
* libpng
* npm (for building packages)

These are all setup by the instructions below for setting up a build
environment.

The project also depends on several bundled node modules.  The build process
takes care of initializing these submodules using "git submodule update --init"
and building the binaries.  IMPORTANT: when attempting to build outside the
normal build environment, be sure to check the output of the "configure" stage
to make sure that node-waf was able to find all the relevant libraries,
particularly for libpng.  If that step fails, it will successfully build the
module without the proper library dependencies, leaving you with an unloadable
module when you try to use the library.


## Workflow

The only supported build environment is an SDC6 "smartos" zone.

1. First, download the latest stock COAL-147. Before building the image, copy a
   public key into usb-headnode/config/config.coal.inc/root.authorized_keys.
   This will allow you to log into the VM, CA zone, and development zone with
   no additional setup.
2. Build the headnode image, boot it, and get it setup. Don't bother with
   `sdc-setup` yet.
3. From the global zone, run:

        /opt/smartdc/agents/lib/node_modules/cabase/tools/devsetup <user>

   This will run `sdc-setup` as needed and set up a zone with your desired
   username. It will take several minutes and then report the new zone's name
   and IP address.
4. If you didn't copy an ssh key into your headnode repo as described in step
   (1) above, copy one to the new development zone right now.
5. On your Macbook, create an ssh configuration for the new zone in `~/.ssh/config`:

        Host devel
            HostName your_zone_ip_address
            ForwardAgent yes

   With `ForwardAgent yes`, you can use "ssh-add" from your Macbook to add your
   ssh keys to your current session and then use these keys from the
   development zone without having to copy the private keys to the zone. You'll
   want this for git.
6. Copy any dotfiles you need (especially .gitconfig and .gitignore to your
   user's home directory).

7. Once the zone is set up:

        # git clone git@git.joyent.com:cloud-analytics.git ca-work
        # cd ca-work
        # gmake xref release

## Running the code

To test out changes to the CA services, you can create a new CA zone from the
release tarball using tools/recreate-zone and sdc-setup.

To test out changes to the CA agent, update it by running this command from the
global zone:

    $SRC/tools/caupagent $SRC/build/dist/ca-*.tar.bz2

where `$SRC` is the full path to your workspace (e.g.,
/zones/.../root/home/.../cloud-analytics).

During development, you can use this more flexible method to test either the
services or the agent:

        # tools/ws
        # export CA_AMQP_PREFIX=cadev
        # node cmd/castashsvc /var/tmp/stash &
        # node cmd/caconfigsvc.js &
        # node cmd/caaggsvc.js &
        # node cmd/cainstsvc.js &

The "ws" tool takes care of setting NODE_PATH appropriately to include all
of our dependencies.  You can choose exactly what you need to run this way.

## Demo

If you just want to play around, try the 'basicvis' demo:

* Use the steps under "Running the Code" below to deploy to a system (e.g.,
  COAL-147).  Take note of the IP address on which you're running the
  configuration and aggregator services and then run:

        # node demo/basicvis/cademo.js -P <IPADDRESS>

* On a machine where you have a web browser (i.e. your laptop), connect to
  http://HOST:23183/ where HOST is the system where you're running the demo.
* You should be able to create and delete graphs for supported merics,
  including scalars, decompositions, and heatmaps.

Alternatively, open up adminui or the portal and look at analytics there.

## Notes

Before checking code in:

- run "gmake pbchk" to check for lint, style, and automated test errors
- make sure that each line in the commit comment contains a JIRA ticket
  number, the ticket synopsis, and nothing else
- if possible, get a code review

All of the interfaces here including command names, arguments, tools, services,
paths, ports, and properties are Unstable and subject to change.

The "jsl" implementation here assumes a Solaris environment and several
Python-related paths.  It should work on a stock COAL-147 local zone.

Dependencies are currently hardcoded in the Makefile.  If you add a new
dependency in deps, be sure to update the Makefile with the necessary targets to
install it into the proto root.

The architecture, API, protocol, and other technical details are
described here:

    https://hub.joyent.com/wiki/display/dev/Introspection

Bugs should be reported in the INTRO (Introspection) bug category.


# Debugging CA with `cactl`

The `cactl` tool is useful for understanding the runtime state of CA services.
`cactl` provides commands for retrieving the status of individual services as
well as aggregated CA state.

You run `cactl` from the global zone like this:

    # cd /opt/smartdc/agents/bin
    # export AMQP_HOST=10.99.99.12
    # ./cactl 

With no arguments, `cactl` will print out detailed usage notes.


# Adding new metrics

## Add the metric

1. First, figure out how to model whatever you're trying to present as a CA
   metric. Pick a module and stat name, and identify the list of fields to
   include and the type of each field.
2. Update the metric metadata in `metadata/metric/metrics.json`. This metadata
   describes the metric so that the UI can automatically list and present all
   metrics. Add any new modules, field types, and fields, then add the actual
   metrics.
3. Update the profile metadata in `metadata/profile/customer.json` and
   `metadata/profile/operator.json`. This metadata describes which metrics and
   fields are available to customers and operators, respectively, as well as
   the order in which they should be presented in the UI.
    * Some metrics may be operator-only, and shouldn't appear in
      customer.json at all. (No metrics should be customer-only.)
    * For most metrics, the metadata is nearly the same for both operators
      and customers **except** that customers are never allowed to see the
      `hostname` field.
4. Implement the metric. See below.
5. **Document the metric** in docs/index.restdown.

The actual metric implementation depends on the type of metric you're adding.

### Adding a DTrace-based metric.

Create a new Meta-D file in `cmd/cainst/modules/dtrace`. You'll probably want
to copy an existing one to start with. Meta-D is documented on the
hub.joyent.com wiki.

### Adding a new kstat-based metric.

Update the definition of `inskMetrics` in `cmd/cainst/kstat.js`. 

## Testing/debugging the new metric

See "Development basics" above for how to run the code.

If you run the new code and the new metric doesn't show up, first verify that
the instrumenter knows about the metric implementation.  You can use the
`cactl` "status" command on an instrumenter to see what metrics it knows about.

If the instrumenter reports the metric, then see if you can see the metric via
the API. If not, the configsvc must not know about it, which either means one
of several things could be wrong:

* The configsvc's copy of the metric metadata does not include the metric. (Did
  you update the CA services with the new metadata?)
* The configsvc's copy of the profile metadata does not include the metric.
* The configsvc doesn't know about an instrumenter that implements the metric.
